nucleoli <- as.vector(apply(as.matrix(data[8], mode="character"),1,paste,"nucleoli",sep="",collapse=""))
mitoses <- as.vector(apply(as.matrix(data[9], mode="character"),1,paste,"mitoses",sep="",collapse=""))
#cbind function takes a sequence of vector and combines by columns or rows
training_data <- cbind(data[10],thick,size,shape,adhesion,single,nuclei,chromatin,nucleoli,mitoses)
# [OPTIONAL] SUBSET YOUR DATA TO GET A RANDOM SAMPLE
# we extract 600 random samples out of the 699
training_data <- training_data[sample(1:699,size=600,replace=FALSE),]
training_codes <- training_data[1]
training_data <- training_data[-1]
#training code contains the label for classification of each document
# CREATE A TERM-DOCUMENT MATRIX THAT REPRESENTS WORD FREQUENCIES IN EACH DOCUMENT
# WE WILL TRAIN ON THE Title and Subject COLUMNS
#format of document term matrix....
#terms t1 t2 t3 t4.....
#docs
#1
#2
#3
#.
#.
matrix <- create_matrix(training_data, language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
matrix
library("tm", lib.loc="~/R/win-library/3.2")
library("RTextTools", lib.loc="~/R/win-library/3.2")
data("crude")
tdm <- TermDocumentMatrix(crude,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(crude,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
data("crude")
library(tm);
library(RTextTools);
data("crude")
tdm <- TermDocumentMatrix(crude,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(crude,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(tdm[202:205, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[1:5, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[1:5, 1:5])
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[1:5, 1:5])
dtm
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[1:5, 1:5])
dtm
container <- create_container(dtm,data$Topic.Code,trainSize=1:10, testSize=11:50,
virgin=FALSE)
library(tm);
library(RTextTools);
data("acq")
tdm <- TermDocumentMatrix(acq,
control = list(removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(acq,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
inspect(dtm[1:5, 1:5])
dtm
container <- create_container(dtm,data$Topic.Code,trainSize=1:10, testSize=11:50,
virgin=FALSE)
container <- create_container(dtm,data$Topic.Code,trainSize=1:10, testSize=11:50,
virgin=FALSE)
library(RTextTools)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
virgin=FALSE)
library(RTextTools)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
View(NYTimes)
library(RTextTools)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
analytics <- create_analytics(container, results)
library(RTextTools);
library(tm);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
library(RTextTools);
library(tm);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
library("RTextTools", lib.loc="~/R/win-library/3.2")
library("SparseM", lib.loc="~/R/win-library/3.2")
library(RTextTools);
library(tm);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
library(RTextTools)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM"))
results <- classify_models(container, models)
library(RTextTools);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM"))
results <- classify_models(container, models)
library(RTextTools);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
library(RTextTools);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
library(RTextTools);
data(NYTimes)
data <- NYTimes[sample(1:3100,size=100,replace=FALSE),]
matrix <- create_matrix(cbind(data["Title"],data["Subject"]), language="english",
removeNumbers=TRUE, stemWords=FALSE, weighting=tm::weightTfIdf)
container <- create_container(matrix,data$Topic.Code,trainSize=1:75, testSize=76:100,
virgin=FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM"))
results <- classify_models(container, models)
analytics <- create_analytics(container, results)
analytics
results
setwd('C:/Users/ddhhrruuvv27/Desktop/Abstract')
require(tm)
fo=file('abstract',open="r")
abstract=readLines(fo)
#fo=file('title',open="r")
#titles=readLines(fo)
corp <- Corpus(VectorSource(abstract))
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(docs,content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs,stemDocument)
docs <- tm_map(docs, stemDocument, language = "english")
dtm <-DocumentTermMatrix(docs,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm = removeSparseTerms(dtm,0.7)
out <- capture.output(inspect(dtm))
options(max.print = 2147483647)
cat("Classification results", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
#train <- sample(nrow(tdm),ceiling(nrow(tdm)* 0.7))
#test <- (1:nrow(tdm))[-train]
freqterms100 <- findFreqTerms(dtm,2)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 2 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,3)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 3 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,4)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 4 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,5)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 5 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
dtm <- as.data.frame(inspect(dtm))
rownames(dtm) <- 1:nrow(dtm)
hundredths <- seq(from=1, to=5, by=1)
label <- sample(hundredths, size=370, replace=TRUE)
container <- create_container(dtm,t(label),trainSize=1:100, testSize=101:370,virgin= FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
out <- capture.output(results)
options(max.print = 2147483647)
cat("#####FINAL RESULYS AFTER CLASSIFICATION#######", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
analytics <- create_analytics(container, results)
out <- capture.output(analytics)
options(max.print = 2147483647)
cat("##################ANALYTICS################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
out <- capture.output(summary(analytics))
options(max.print = 2147483647)
cat("#######################################################################################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
setwd('C:/Users/ddhhrruuvv27/Desktop/Final_Presentation')
require(tm)
fo=file('Abstract',open="r")
Abstract=readLines(fo)
#fo=file('title',open="r")
#titles=readLines(fo)
corp <- Corpus(VectorSource(Abstract))
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(docs,content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs,stemDocument)
docs <- tm_map(docs, stemDocument, language = "english")
dtm <-DocumentTermMatrix(docs,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
library("RTextTools", lib.loc="~/R/win-library/3.2")
library("SnowballC", lib.loc="~/R/win-library/3.2")
library("SparseM", lib.loc="~/R/win-library/3.2")
library("stylo", lib.loc="~/R/win-library/3.2")
library("e1071", lib.loc="~/R/win-library/3.2")
library("class", lib.loc="C:/Program Files/R/R-3.2.3/library")
setwd('C:/Users/ddhhrruuvv27/Desktop/Final_Presentation')
require(tm)
fo=file('Abstract',open="r")
Abstract=readLines(fo)
#fo=file('title',open="r")
#titles=readLines(fo)
corp <- Corpus(VectorSource(Abstract))
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(docs,content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs,stemDocument)
docs <- tm_map(docs, stemDocument, language = "english")
dtm <-DocumentTermMatrix(docs,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
setwd('C:/Users/ddhhrruuvv27/Desktop/Doc')
require(tm)
fo=file('doc',open="r")
doc=readLines(fo)
#fo=file('title',open="r")
#titles=readLines(fo)
corp <- Corpus(VectorSource(doc))
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(docs,content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs,stemDocument)
docs <- tm_map(docs, stemDocument, language = "english")
dtm <-DocumentTermMatrix(docs,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
inspect(dtm)
dtm = removeSparseTerms(dtm,0.7)
out <- capture.output(inspect(dtm))
options(max.print = 2147483647)
cat("Classification results", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,2)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 2 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,3)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 3 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,4)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 4 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,5)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 5 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
rownames(dtm) <- 1:nrow(dtm)
View(dtm)
dtm <- as.data.frame(inspect(dtm))
rownames(dtm) <- 1:nrow(dtm)
View(dtm)
vector <- c(1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6)
vector
ncol(vector)
size(vector)
container <- create_container(dtm,t(vector),trainSize=1:100, testSize=101:370,virgin= FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
out <- capture.output(results)
options(max.print = 2147483647)
cat("#####FINAL RESULYS AFTER CLASSIFICATION#######", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
analytics <- create_analytics(container, results)
out <- capture.output(analytics)
options(max.print = 2147483647)
cat("##################ANALYTICS################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
out <- capture.output(summary(analytics))
options(max.print = 2147483647)
cat("#######################################################################################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
container <- create_container(dtm,t(vector),trainSize=1:20, testSize=21:55,virgin= FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
out <- capture.output(results)
options(max.print = 2147483647)
cat("#####FINAL RESULYS AFTER CLASSIFICATION#######", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
analytics <- create_analytics(container, results)
out <- capture.output(analytics)
options(max.print = 2147483647)
cat("##################ANALYTICS################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
out <- capture.output(summary(analytics))
options(max.print = 2147483647)
cat("#######################################################################################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
setwd('C:/Users/ddhhrruuvv27/Desktop/Doc')
require(tm)
fo=file('doc',open="r")
doc=readLines(fo)
#fo=file('title',open="r")
#titles=readLines(fo)
corp <- Corpus(VectorSource(doc))
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(docs,content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs,stemDocument)
docs <- tm_map(docs, stemDocument, language = "english")
dtm <-DocumentTermMatrix(docs,control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm = removeSparseTerms(dtm,0.7)
out <- capture.output(inspect(dtm))
options(max.print = 2147483647)
cat("Classification results", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,2)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 2 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,3)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 3 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,4)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 4 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
freqterms100 <- findFreqTerms(dtm,5)
out <- capture.output(freqterms100)
options(max.print = 2147483647)
cat("Frequent terms in atleast 5 documents", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
dtm <- as.data.frame(inspect(dtm))
rownames(dtm) <- 1:nrow(dtm)
vector <- c(1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6)
container <- create_container(dtm,t(vector),trainSize=1:20, testSize=21:55,virgin= FALSE)
models <- train_models(container, algorithms=c("MAXENT","SVM","GLMNET","SLDA","TREE","BAGGING","BOOSTING","RF"))
results <- classify_models(container, models)
out <- capture.output(results)
options(max.print = 2147483647)
cat("#####FINAL RESULYS AFTER CLASSIFICATION#######", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
analytics <- create_analytics(container, results)
out <- capture.output(analytics)
options(max.print = 2147483647)
cat("##################ANALYTICS################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
out <- capture.output(summary(analytics))
options(max.print = 2147483647)
cat("#######################################################################################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
cat("#######################################################################################", out, file="results_finalfinal.txt", sep="\n", append=TRUE)
View(dtm)
